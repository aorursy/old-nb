import numpy as np 

import pandas as pd

import json

import bq_helper

from pandas.io.json import json_normalize

import seaborn as sns 

from plotly.offline import init_notebook_mode, iplot

import plotly.graph_objs as go

from plotly import tools

import numpy as np

init_notebook_mode(connected=True)

import matplotlib as mpl

import matplotlib.pyplot as plt


import scipy.stats as st

import missingno as msno
df_train = pd.read_csv("../input/train.csv",sep=',')

df_test = pd.read_csv("../input/test.csv",sep=',')
df_train.head()
df_test.head()
json_columns = ['device', 'geoNetwork','totals', 'trafficSource']

def load_dataframe(filename):

    path = "../input/" + filename

    df = pd.read_csv(path, converters={column: json.loads for column in json_columns}, 

                     dtype={'fullVisitorId': 'str'})

   

    for column in json_columns:

        column_as_df = json_normalize(df[column])

        column_as_df.columns = [f"{column}_{subcolumn}" for subcolumn in column_as_df.columns]

        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)

    return df
train = load_dataframe("train.csv")

train.head()
test = load_dataframe("test.csv")

test.head()
print(train.info(),test.info())
print(train.shape,test.shape)
numeric_features_train = train.select_dtypes(include=[np.number])

numeric_features_train.columns
numeric_features_test = test.select_dtypes(include=[np.number])



numeric_features_test.columns
categorical_features_train = train.select_dtypes(include=[np.object])

categorical_features_train.columns
categorical_features_test = test.select_dtypes(include=[np.object])

categorical_features_test.columns
print ("Before removing constant columns - shape of train & test datasets: ", train.shape,test.shape)

train = train.loc[:, (train != train.iloc[0]).any()]

test = test.loc[:, (test != test.iloc[0]).any()]

print ("After Removing Constant Columns - shape of train & test datasets: ", train.shape,test.shape)
total_test = categorical_features_train.isnull().sum().sort_values(ascending=False)

percent = (categorical_features_train.isnull().sum()/categorical_features_train.isnull().count()).sort_values(ascending=False)*100

missing_data = pd.concat([total_test, percent], axis=1,join='outer', keys=['Total Missing Count', ' % of Total Observations'])

missing_data.index.name ='Feature'

missing_data.head(14)
missing_values = categorical_features_train.isnull().sum(axis=0).reset_index()

missing_values.columns = ['column_name', 'missing_count']

missing_values = missing_values.loc[missing_values['missing_count']>0]

missing_values = missing_values.sort_values(by='missing_count')

ind = np.arange(missing_values.shape[0])

width = 0.1

fig, ax = plt.subplots(figsize=(12,3))

rects = ax.barh(ind, missing_values.missing_count.values, color='b')

ax.set_yticks(ind)

ax.set_yticklabels(missing_values.column_name.values, rotation='horizontal')

ax.set_xlabel("Missing Observations Count")

ax.set_title("Missing Categorical Observations in Train Dataset")

plt.show()
total_test = categorical_features_test.isnull().sum().sort_values(ascending=False)

percent = (categorical_features_test.isnull().sum()/categorical_features_test.isnull().count()).sort_values(ascending=False)*100

missing_data = pd.concat([total_test, percent], axis=1,join='outer', keys=['Total Missing Count', ' % of Total Observations'])

missing_data.index.name ='Feature'

missing_data.head(12)
missing_values = categorical_features_test.isnull().sum(axis=0).reset_index()

missing_values.columns = ['column_name', 'missing_count']

missing_values = missing_values.loc[missing_values['missing_count']>0]

missing_values = missing_values.sort_values(by='missing_count')

ind = np.arange(missing_values.shape[0])

width = 0.1

fig, ax = plt.subplots(figsize=(12,3))

rects = ax.barh(ind, missing_values.missing_count.values, color='b')

ax.set_yticks(ind)

ax.set_yticklabels(missing_values.column_name.values, rotation='horizontal')

ax.set_xlabel("Missing Observations Count")

ax.set_title("Missing Categorical Observations in Test Dataset")

plt.show()
colorscale = [[0, 'rgb(102,194,165)'], [0.0005, 'rgb(102,194,165)'], 

              [0.01, 'rgb(171,221,164)'], [0.02, 'rgb(230,245,152)'], 

              [0.04, 'rgb(255,255,191)'], [0.05, 'rgb(254,224,139)'], 

              [0.10, 'rgb(253,174,97)'], [0.25, 'rgb(213,62,79)'], [1.0, 'rgb(158,1,66)']]



data = [ dict(

        type = 'choropleth',

        autocolorscale = False,

        colorscale = colorscale,

        showscale = True,

        locations = train["geoNetwork_country"].value_counts().index,

        locationmode = 'country names',

        z = train["geoNetwork_country"].value_counts().values,

        marker = dict(

            line = dict(color = 'rgb(250,250,225)', width = 1)),

            colorbar = dict( title = 'Customer Visits ')

            ) 

       ]



layout = dict(

    height=600,

    title = 'World Wide Customer Visit Distribution',

    geo = dict(

        showframe = True,

        showocean = True,

        oceancolor = 'rgb(28,107,160)',

        projection = dict(

        type = 'orthographic',

            rotation = dict(

                    lon = 50,

                    lat = 10),

        ),

        lonaxis =  dict(

                showgrid = True,

                gridcolor = 'rgb(12, 102, 102)'

            ),

        lataxis = dict(

                showgrid = True,

                gridcolor = 'rgb(12, 102, 102)'

                )

            ),

        )

fig = dict(data=data, layout=layout)

iplot(fig)
colorscale = [[0, 'rgb(102,194,165)'], [0.0005, 'rgb(102,194,165)'], 

              [0.01, 'rgb(171,221,164)'], [0.02, 'rgb(230,245,152)'], 

              [0.04, 'rgb(255,255,191)'], [0.05, 'rgb(254,224,139)'], 

              [0.10, 'rgb(253,174,97)'], [0.25, 'rgb(213,62,79)'], [1.0, 'rgb(158,1,66)']]



data = [ dict(

        type = 'choropleth',

        autocolorscale = False,

        colorscale = colorscale,

        showscale = True,

        locations = train["geoNetwork_country"].value_counts().index,

        locationmode = 'country names',

        z = train["geoNetwork_country"].value_counts().values,

        marker = dict(

            line = dict(color = 'rgb(250,250,225)', width = 1)),

            colorbar = dict( title = 'Customer Visits ')

            ) 

       ]



layout = dict(

    height=600,

    title = 'World Wide Customer Visit Distribution',

    geo = dict(

        showframe = True,

        showocean = True,

        oceancolor = 'rgb(28,107,160)',

        projection = dict(

        type = 'conic equal area',

            rotation = dict(

                    lon = 50,

                    lat = 10),

        ),

        lonaxis =  dict(

                showgrid = True,

                gridcolor = 'rgb(12, 102, 102)'

            ),

        lataxis = dict(

                showgrid = True,

                gridcolor = 'rgb(12, 102, 102)'

                )

            ),

        )

fig = dict(data=data, layout=layout)

iplot(fig)
geo_cols = ["geoNetwork_city", "geoNetwork_country", "geoNetwork_subContinent", "geoNetwork_continent"]

colors = ["#d6a5ff", "#fca6da", "#f4d39c", "#a9fcca"]

traces = []

for i, col in enumerate(geo_cols):

    t = train[col].value_counts()

    traces.append(go.Bar(marker=dict(color=colors[i]),orientation="h", y = t.index[:15], x = t.values[:15]))



fig = tools.make_subplots(rows=2, cols=2, 

                          subplot_titles=["Visits: City", "Visits: Country","Visits: Sub Continent","Visits: Continent"]

                          , print_grid=False)

fig.append_trace(traces[0], 1, 1)

fig.append_trace(traces[1], 1, 2)

fig.append_trace(traces[2], 2, 1)

fig.append_trace(traces[3], 2, 2)



fig['layout'].update(height=600,width=1000, showlegend=False)

iplot(fig)



train["totals_transactionRevenue"] = train["totals_transactionRevenue"].astype('float')



fig = tools.make_subplots(rows=2, cols=2, subplot_titles=["Mean Revenue by City", "Mean Revenue by Country","Mean Revenue by Sub Continent","Mean Revenue by Continent"], print_grid=False)



colors = ["red", "green", "purple","blue"]

trs = []

for i, col in enumerate(geo_cols):

    tmp = train.groupby(col).agg({"totals_transactionRevenue": "mean"}).reset_index().rename(columns={"totals_transactionRevenue" : "Mean Revenue"})

    tmp = tmp.dropna()

    tr = go.Bar(x = tmp["Mean Revenue"], orientation="h", marker=dict(opacity=0.5, color=colors[i]), y = tmp[col])

    trs.append(tr)



fig.append_trace(trs[0], 1, 1)

fig.append_trace(trs[1], 1, 2)

fig.append_trace(trs[2], 2, 1)

fig.append_trace(trs[3], 2, 2)



fig['layout'].update(height=600,width=1000, showlegend=False)

iplot(fig)
t = train['channelGrouping'].value_counts()

values1 = t.values 

index1 = t.index

domain1 = {'x': [0.2, 0.50], 'y': [0.0, 0.33]}

fig = {

  "data": [

    {

      "values": values1,

      "labels": index1,

      "domain": {"x": [0, .48]},

    "marker" : dict(colors=["#f77b9c" ,'#ab97db',  '#b0b1b2']),

      "name": "Channel Grouping",

      "hoverinfo":"label+percent+name",

      "hole": .7,

      "type": "pie"

    }

   ],

  "layout": {"title":"Channel Grouping",

      "annotations": [

            {

                "font": {

                    "size": 20

                },

                "showarrow": False,

                "text": "Channel Grouping",

                "x": 0.11,

                "y": 0.5

            }

        ]

    }

}

iplot(fig)
fig = tools.make_subplots(rows=1, cols=2,subplot_titles=["Traffic Source Campaign (not-set removed)", "Traffic Source Medium"], print_grid=False)

 

colors = ["#d6a5ff", "#fca6da", "#f4d39c", "#a9fcca"]

t1 = train["trafficSource_campaign"].value_counts()

t2 = train["trafficSource_medium"].value_counts()



tr1 = go.Bar(x = t1.index, y = t1.values, marker=dict(color=colors[1]))

tr2 = go.Bar(x = t2.index, y = t2.values, marker=dict(color=colors[2]))



fig.append_trace(tr1, 1, 1)

fig.append_trace(tr2, 1, 2)





fig['layout'].update(height=400, margin=dict(b=100), showlegend=False)

iplot(fig)
def add_date_features(df):

    df['date'] = df['date'].astype(str)

    df["date"] = df["date"].apply(lambda x : x[:4] + "-" + x[4:6] + "-" + x[6:])

    df["date"] = pd.to_datetime(df["date"])

    

    df["month"]   = df['date'].dt.month

    df["day"]     = df['date'].dt.day

    df["weekday"] = df['date'].dt.weekday

    return df 
train = add_date_features(train)
# Visualization for Visits by date

tmp = train['date'].value_counts().to_frame().reset_index().sort_values('index')

tmp = tmp.rename(columns = {"index" : "dateX", "date" : "visits"})



tr = go.Scatter(mode="lines", x = tmp["dateX"].astype(str), y = tmp["visits"])

layout = go.Layout(title="Visits by Date", height=400)

fig = go.Figure(data = [tr], layout = layout)

iplot(fig)

# Visualization for Visits by monthly revenue

tmp = train.groupby("date").agg({"totals_transactionRevenue" : "mean"}).reset_index()

tmp = tmp.rename(columns = {"date" : "dateX", "totals_transactionRevenue" : "mean_revenue"})

tr = go.Scatter(mode="lines", x = tmp["dateX"].astype(str), y = tmp["mean_revenue"])

layout = go.Layout(title="Monthly Revenue by Date", height=400)

fig = go.Figure(data = [tr], layout = layout)

iplot(fig)
fig = tools.make_subplots(rows=1, cols=3, subplot_titles=["Visits by Month", "Visits by Month Day", "Visits by Week Day"], print_grid=False)

trs = []

for i,col in enumerate(["month", "day", "weekday"]):

    t = train[col].value_counts()

    tr = go.Bar(x = t.index, marker=dict(color=colors[i]), y = t.values)

    trs.append(tr)



fig.append_trace(trs[0], 1, 1)

fig.append_trace(trs[1], 1, 2)

fig.append_trace(trs[2], 1, 3)

fig['layout'].update(height=400, showlegend=False)

iplot(fig)
tmp1 = train.groupby('month').agg({"totals_transactionRevenue" : "mean"}).reset_index()

tmp2 = train.groupby('day').agg({"totals_transactionRevenue" : "mean"}).reset_index()

tmp3 = train.groupby('weekday').agg({"totals_transactionRevenue" : "mean"}).reset_index()



fig = tools.make_subplots(rows=1, cols=3, subplot_titles=["MeanRevenue by Month", "MeanRevenue by MonthDay", "MeanRevenue by WeekDay"], print_grid=False)

tr1 = go.Bar(x = tmp1.month, marker=dict(color="yellow", opacity=0.5), y = tmp1.totals_transactionRevenue)

tr2 = go.Bar(x = tmp2.day, marker=dict(color="blue", opacity=0.5), y = tmp2.totals_transactionRevenue)

tr3 = go.Bar(x = tmp3.weekday, marker=dict(color="violet", opacity=0.5), y = tmp3.totals_transactionRevenue)



fig.append_trace(tr1, 1, 1)

fig.append_trace(tr2, 1, 2)

fig.append_trace(tr3, 1, 3)

fig['layout'].update(height=400, showlegend=False)

iplot(fig)
import warnings

warnings.simplefilter(action='ignore', category=FutureWarning)



agg_dict = {}

for col in ["totals_bounces", "totals_hits", "totals_newVisits", "totals_pageviews", "totals_transactionRevenue"]:

    train[col] = train[col].astype('float')

    agg_dict[col] = "sum"

tmp = train.groupby("fullVisitorId").agg(agg_dict).reset_index()

tmp.head()
non_zero = tmp[tmp["totals_transactionRevenue"] > 0]["totals_transactionRevenue"]

print ("There are " + str(len(non_zero)) + " visitors in the train dataset having non zero total transaction revenue")



plt.figure(figsize=(10,6))

sns.distplot(non_zero)

plt.title("Distribution of Non-Zero Total Transactions");

plt.xlabel("Total Transactions");
plt.figure(figsize=(12,6))

sns.distplot(np.log1p(non_zero))

plt.title("Natural Log Distribution of Non Zero Total Transactions");

plt.xlabel("Natural Log - Total Transactions");
## find constant columns

constant_columns = []

for col in train.columns:

    if len(train[col].value_counts()) == 1:

        constant_columns.append(col)



## non relevant columns

non_relevant = ["visitNumber", "date", "fullVisitorId", "sessionId", "visitId", "visitStartTime"]
test = add_date_features(test)
from sklearn.preprocessing import LabelEncoder



categorical_columns = [c for c in train.columns if not c.startswith("total")]

categorical_columns = [c for c in categorical_columns if c not in constant_columns + non_relevant]

for c in categorical_columns:



    le = LabelEncoder()

    train_vals = list(train[c].values.astype(str))

    test_vals = list(test[c].values.astype(str))

    

    le.fit(train_vals + test_vals)

    

    train[c] = le.transform(train_vals)

    test[c] = le.transform(test_vals)
def normalize_numerical_columns(df, isTrain = True):

    df["totals_hits"] = df["totals_hits"].astype(float)

    df["totals_hits"] = (df["totals_hits"] - min(df["totals_hits"])) / (max(df["totals_hits"]) - min(df["totals_hits"]))



    df["totals_pageviews"] = df["totals_pageviews"].astype(float)

    df["totals_pageviews"] = (df["totals_pageviews"] - min(df["totals_pageviews"])) / (max(df["totals_pageviews"]) - min(df["totals_pageviews"]))

    

    if isTrain:

        df["totals_transactionRevenue"] = df["totals_transactionRevenue"].fillna(0.0)

    return df 
train = normalize_numerical_columns(train)

test = normalize_numerical_columns(test, isTrain = False)
from sklearn.model_selection import train_test_split

features = [c for c in train.columns if c not in constant_columns + non_relevant]

features.remove("totals_transactionRevenue")

train["totals_transactionRevenue"] = np.log1p(train["totals_transactionRevenue"].astype(float))

train_x, valid_x, train_y, valid_y = train_test_split(train[features], train["totals_transactionRevenue"], test_size=0.25, random_state=20)
import lightgbm as lgb 



lgb_params = {"objective" : "regression", "metric" : "rmse",

              "num_leaves" : 50, "learning_rate" : 0.02, 

              "bagging_fraction" : 0.75, "feature_fraction" : 0.8, "bagging_frequency" : 9}

    

lgb_train = lgb.Dataset(train_x, label=train_y)

lgb_val = lgb.Dataset(valid_x, label=valid_y)

model = lgb.train(lgb_params, lgb_train, 700, valid_sets=[lgb_val], early_stopping_rounds=150, verbose_eval=20)
preds = model.predict(test[features], num_iteration=model.best_iteration)

test["PredictedLogRevenue"] = np.expm1(preds)

submission = test.groupby("fullVisitorId").agg({"PredictedLogRevenue" : "sum"}).reset_index()

submission["PredictedLogRevenue"] = np.log1p(submission["PredictedLogRevenue"])

submission["PredictedLogRevenue"] =  submission["PredictedLogRevenue"].apply(lambda x : 0.0 if x < 0 else x)

submission.to_csv("baseline.csv", index=False)

submission.head()