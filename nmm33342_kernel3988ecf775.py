# This Python 3 environment comes with many helpful analytics libraries installed

# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python

# For example, here's several helpful packages to load in 



import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import re

import string

import nltk

from nltk.corpus import stopwords



# Graphics

import matplotlib.pyplot as plt

import seaborn as sns

from wordcloud import WordCloud, STOPWORDS






# Input data files are available in the "../input/" directory.

# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory



import os

print(os.listdir("../input"))



# Any results you write to the current directory are saved as output.
train = pd.read_csv('../input/labeledTrainData.tsv', delimiter='\t')

test = pd.read_csv('../input/testData.tsv', delimiter='\t')



train.shape, test.shape
train.head()
train['review'][1]
print ("number of rows for sentiment 1: {}".format(len(train[train.sentiment == 1])))

print ( "number of rows for sentiment 0: {}".format(len(train[train.sentiment == 0])))
train.groupby('sentiment').describe().T
train['length'] = train['review'].apply(len)

train.head()
train['length'].plot.hist(bins=100);
train.describe()
train.hist(column='length', by='sentiment', bins=100);
from bs4 import BeautifulSoup



#Creating a function for cleaning of data

def clean_text(raw_text):

    # 1. remove HTML tags

    raw_text = BeautifulSoup(raw_text, 'lxml').get_text() 

    

    # 2. removing all non letters from text

    letters_only = re.sub("[^a-zA-Z]", " ", raw_text) 

    

    # 3. Convert to lower case, split into individual words

    words = letters_only.lower().split()                           

    

    # 4. Create variable which contain set of stopwords

    stops = set(stopwords.words("english"))                  

    

    # 5. Remove stop word & returning   

    return [w for w in words if not w in stops]
train['clean_review'] = train['review'].apply(clean_text)

train['length_clean_review'] = train['clean_review'].apply(len)

train.head()
train.describe()
print(train[train['length_clean_review'] == 4]['review'].iloc[0])

print('------After Cleaning------')

print(train[train['length_clean_review'] == 4]['clean_review'].iloc[0])
word_cloud = WordCloud(width = 1000, height = 500, stopwords = STOPWORDS, background_color = 'red').generate(

                        ''.join(train['review']))



plt.figure(figsize = (15,8))

plt.imshow(word_cloud)

plt.axis('off')

plt.show()
from sklearn.feature_extraction.text import CountVectorizer
# Might take awhile...

bow_transform = CountVectorizer(analyzer=clean_text).fit(train['review'])  #bow = bag of word



# Print total number of vocab words

print(len(bow_transform.vocabulary_))
review1 = train['review'][2]

print(review1)
bow1 = bow_transform.transform([review1])

print(bow1)

print(bow1.shape)
review_bow = bow_transform.transform(train['review'])
print('Shape of Sparse Matrix: ', review_bow.shape)

print('Amount of Non-Zero occurences: ', review_bow.nnz)
sparsity = (100.0 * review_bow.nnz / (review_bow.shape[0] * review_bow.shape[1]))

print('sparsity: {}'.format(sparsity))
from sklearn.feature_extraction.text import TfidfTransformer



tfidf_transformer = TfidfTransformer().fit(review_bow)

tfidf1 = tfidf_transformer.transform(bow1)

print(tfidf1)
review_tfidf = tfidf_transformer.transform(review_bow)

print(review_tfidf.shape)
from sklearn.model_selection import train_test_split



X_train, X_test, y_train, y_test = train_test_split(train['review'], train['sentiment'], test_size=0.22, random_state=101)



len(X_train), len(X_test), len(X_train) + len(X_test)
from sklearn.metrics import classification_report

#Predicting & Stats Function

def pred(predicted,compare):

    cm = pd.crosstab(compare,predicted)

    TN = cm.iloc[0,0]

    FN = cm.iloc[1,0]

    TP = cm.iloc[1,1]

    FP = cm.iloc[0,1]

    print("CONFUSION MATRIX ------->> ")

    print(cm)

    print()

    

    ##check accuracy of model

    print('Classification paradox :------->>')

    print('Accuracy :- ', round(((TP+TN)*100)/(TP+TN+FP+FN),2))

    print()

    print('False Negative Rate :- ',round((FN*100)/(FN+TP),2))

    print()

    print('False Postive Rate :- ',round((FP*100)/(FP+TN),2))

    print()

    print(classification_report(compare,predicted))
from sklearn.linear_model import LogisticRegression

from sklearn.pipeline import Pipeline



pipeline = Pipeline([

    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts

    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores

    ('classifier', LogisticRegression(random_state=101)),  # train on TF-IDF vectors w/ Naive Bayes classifier

])



pipeline.fit(X_train,y_train)

predictions = pipeline.predict(X_train)

pred(predictions,y_train)
#Test Set Result

predictions = pipeline.predict(X_test)

pred(predictions,y_test)
from sklearn.naive_bayes import MultinomialNB



pipeline = Pipeline([

    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts

    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores

    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier

])



pipeline.fit(X_train,y_train)

predictions = pipeline.predict(X_train)

pred(predictions,y_train)
#Result on Test Case

predictions = pipeline.predict(X_test)

pred(predictions,y_test)
from sklearn.ensemble import RandomForestClassifier



pipeline = Pipeline([

    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts

    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores

    ('classifier', RandomForestClassifier(n_estimators = 500)),  # train on TF-IDF vectors w/ Naive Bayes classifier

])



pipeline.fit(X_train,y_train)

predictions = pipeline.predict(X_train)

pred(predictions,y_train)
#Test Set Result

predictions = pipeline.predict(X_test)

pred(predictions,y_test)
from sklearn.linear_model import LogisticRegression

from sklearn.pipeline import Pipeline



pipeline_logit = Pipeline([

    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts

    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores

    ('classifier', LogisticRegression(random_state=101)),  # train on TF-IDF vectors w/ Naive Bayes classifier

])



pipeline_logit.fit(train['review'],train['sentiment'])

test['sentiment'] = pipeline_logit.predict(test['review'])
test.head(5)
output = test[['id','sentiment']]

print(output)
output.to_csv( "output.csv", index=False, quoting=3 )